{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "64bc3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#モデルの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "#正規化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "312a890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSVファイルの読み込み\n",
    "dataset = pd.read_csv(\"atp_tennis.csv\")\n",
    "# datasetの型を確認\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5dac64aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Player_1</th>\n",
       "      <th>Player_2</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Rank_1</th>\n",
       "      <th>Rank_2</th>\n",
       "      <th>Pts_1</th>\n",
       "      <th>Pts_2</th>\n",
       "      <th>Odd_1</th>\n",
       "      <th>Odd_2</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>Ljubicic I.</td>\n",
       "      <td>Dosedel S.</td>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6-4 6-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Clement A.</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3-6 3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>Baccanello P.</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>40</td>\n",
       "      <td>655</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6-7 7-5 6-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Knippschild J.</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>Federer R.</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1-6 4-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>Woodbridge T.</td>\n",
       "      <td>Fromberg R.</td>\n",
       "      <td>81</td>\n",
       "      <td>198</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7-6 5-7 6-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Tournament        Date         Series    Court  \\\n",
       "0  Australian Hardcourt Championships  2000-01-03  International  Outdoor   \n",
       "1  Australian Hardcourt Championships  2000-01-03  International  Outdoor   \n",
       "2  Australian Hardcourt Championships  2000-01-03  International  Outdoor   \n",
       "3  Australian Hardcourt Championships  2000-01-03  International  Outdoor   \n",
       "4  Australian Hardcourt Championships  2000-01-03  International  Outdoor   \n",
       "\n",
       "  Surface      Round  Best of        Player_1       Player_2       Winner  \\\n",
       "0    Hard  1st Round        3      Dosedel S.    Ljubicic I.   Dosedel S.   \n",
       "1    Hard  1st Round        3      Clement A.     Enqvist T.   Enqvist T.   \n",
       "2    Hard  1st Round        3       Escude N.  Baccanello P.    Escude N.   \n",
       "3    Hard  1st Round        3  Knippschild J.     Federer R.   Federer R.   \n",
       "4    Hard  1st Round        3     Fromberg R.  Woodbridge T.  Fromberg R.   \n",
       "\n",
       "   Rank_1  Rank_2  Pts_1  Pts_2  Odd_1  Odd_2        Score  \n",
       "0      63      77     -1     -1   -1.0   -1.0      6-4 6-2  \n",
       "1      56       5     -1     -1   -1.0   -1.0      3-6 3-6  \n",
       "2      40     655     -1     -1   -1.0   -1.0  6-7 7-5 6-3  \n",
       "3      87      65     -1     -1   -1.0   -1.0      1-6 4-6  \n",
       "4      81     198     -1     -1   -1.0   -1.0  7-6 5-7 6-4  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最初の5行を表示\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f0f32acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66681 entries, 0 to 66680\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Tournament  66681 non-null  object \n",
      " 1   Date        66681 non-null  object \n",
      " 2   Series      66681 non-null  object \n",
      " 3   Court       66681 non-null  object \n",
      " 4   Surface     66681 non-null  object \n",
      " 5   Round       66681 non-null  object \n",
      " 6   Best of     66681 non-null  int64  \n",
      " 7   Player_1    66681 non-null  object \n",
      " 8   Player_2    66681 non-null  object \n",
      " 9   Winner      66681 non-null  object \n",
      " 10  Rank_1      66681 non-null  int64  \n",
      " 11  Rank_2      66681 non-null  int64  \n",
      " 12  Pts_1       66681 non-null  int64  \n",
      " 13  Pts_2       66681 non-null  int64  \n",
      " 14  Odd_1       66681 non-null  float64\n",
      " 15  Odd_2       66681 non-null  float64\n",
      " 16  Score       66681 non-null  object \n",
      "dtypes: float64(2), int64(5), object(10)\n",
      "memory usage: 8.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Tournament', 'Date', 'Series', 'Court', 'Surface', 'Round',\n",
       "       'Best of', 'Player_1', 'Player_2', 'Winner', 'Rank_1', 'Rank_2',\n",
       "       'Pts_1', 'Pts_2', 'Odd_1', 'Odd_2', 'Score'], dtype=object)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの形状を確認\n",
    "dataset.shape\n",
    "# 全体的な情報を表示\n",
    "dataset.info()\n",
    "# 列ラベルを確認\n",
    "dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5aa711fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best of</th>\n",
       "      <th>Rank_1</th>\n",
       "      <th>Rank_2</th>\n",
       "      <th>Pts_1</th>\n",
       "      <th>Pts_2</th>\n",
       "      <th>Odd_1</th>\n",
       "      <th>Odd_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>66681.000000</td>\n",
       "      <td>66681.000000</td>\n",
       "      <td>66681.000000</td>\n",
       "      <td>66681.000000</td>\n",
       "      <td>66681.000000</td>\n",
       "      <td>66681.000000</td>\n",
       "      <td>66681.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.377529</td>\n",
       "      <td>75.846103</td>\n",
       "      <td>75.543543</td>\n",
       "      <td>1134.708973</td>\n",
       "      <td>1139.502527</td>\n",
       "      <td>2.414427</td>\n",
       "      <td>2.411957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.782649</td>\n",
       "      <td>100.610092</td>\n",
       "      <td>100.879448</td>\n",
       "      <td>1721.139941</td>\n",
       "      <td>1744.762999</td>\n",
       "      <td>2.660011</td>\n",
       "      <td>2.640809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>1.333000</td>\n",
       "      <td>1.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1.736667</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1253.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3390.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>16950.000000</td>\n",
       "      <td>16950.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Best of        Rank_1        Rank_2         Pts_1         Pts_2  \\\n",
       "count  66681.000000  66681.000000  66681.000000  66681.000000  66681.000000   \n",
       "mean       3.377529     75.846103     75.543543   1134.708973   1139.502527   \n",
       "std        0.782649    100.610092    100.879448   1721.139941   1744.762999   \n",
       "min        3.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "25%        3.000000     24.000000     24.000000    117.000000    120.000000   \n",
       "50%        3.000000     53.000000     54.000000    701.000000    701.000000   \n",
       "75%        3.000000     92.000000     92.000000   1250.000000   1253.000000   \n",
       "max        5.000000   3390.000000   4915.000000  16950.000000  16950.000000   \n",
       "\n",
       "              Odd_1         Odd_2  \n",
       "count  66681.000000  66681.000000  \n",
       "mean       2.414427      2.411957  \n",
       "std        2.660011      2.640809  \n",
       "min       -1.000000     -1.000000  \n",
       "25%        1.333000      1.333000  \n",
       "50%        1.736667      1.800000  \n",
       "75%        2.750000      2.750000  \n",
       "max       67.000000     51.000000  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要約統計量を表示\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3ad504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ準備\n",
    "dataset = dataset[(dataset['Rank_1'] > 0) & (dataset['Rank_2'] > 0) & (dataset['Odd_1'] > 0) & (dataset['Odd_2'] > 0)]\n",
    "dataset['target'] = (dataset['Winner'] == dataset['Player_1']).astype(int)\n",
    "\n",
    "feature_cols = ['Rank_1', 'Rank_2', 'Pts_1', 'Pts_2', 'Odd_1', 'Odd_2']\n",
    "X = dataset[feature_cols]\n",
    "y = dataset['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "68e012b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ※データの正規化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "21d74de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ocean\\Documents\\aidev\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# モデル構築\n",
    "model = Sequential()\n",
    "\n",
    "# 入力層\n",
    "model.add(Dense(16, activation='relu', input_shape=(6,)))\n",
    "\n",
    "# 隠れ層\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# 出力層（2択の問題=1, sigmoid ）\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2975f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習前の設定（keras）\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d1b106c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 847us/step - accuracy: 0.6900 - loss: 0.5818 - val_accuracy: 0.6886 - val_loss: 0.5797\n",
      "Epoch 2/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.6971 - loss: 0.5726 - val_accuracy: 0.6893 - val_loss: 0.5763\n",
      "Epoch 3/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.6972 - loss: 0.5718 - val_accuracy: 0.6910 - val_loss: 0.5773\n",
      "Epoch 4/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.6967 - loss: 0.5713 - val_accuracy: 0.6899 - val_loss: 0.5762\n",
      "Epoch 5/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.6967 - loss: 0.5713 - val_accuracy: 0.6903 - val_loss: 0.5771\n",
      "Epoch 6/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6969 - loss: 0.5711 - val_accuracy: 0.6903 - val_loss: 0.5762\n",
      "Epoch 7/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6972 - loss: 0.5708 - val_accuracy: 0.6905 - val_loss: 0.5761\n",
      "Epoch 8/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.6964 - loss: 0.5709 - val_accuracy: 0.6913 - val_loss: 0.5760\n",
      "Epoch 9/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6972 - loss: 0.5707 - val_accuracy: 0.6889 - val_loss: 0.5778\n",
      "Epoch 10/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6957 - loss: 0.5708 - val_accuracy: 0.6912 - val_loss: 0.5780\n",
      "Epoch 11/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.6968 - loss: 0.5707 - val_accuracy: 0.6909 - val_loss: 0.5762\n",
      "Epoch 12/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.6972 - loss: 0.5705 - val_accuracy: 0.6908 - val_loss: 0.5768\n",
      "Epoch 13/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.6970 - loss: 0.5706 - val_accuracy: 0.6906 - val_loss: 0.5757\n",
      "Epoch 14/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6975 - loss: 0.5706 - val_accuracy: 0.6915 - val_loss: 0.5760\n",
      "Epoch 15/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.6976 - loss: 0.5706 - val_accuracy: 0.6902 - val_loss: 0.5764\n",
      "Epoch 16/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6967 - loss: 0.5705 - val_accuracy: 0.6897 - val_loss: 0.5776\n",
      "Epoch 17/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6975 - loss: 0.5705 - val_accuracy: 0.6899 - val_loss: 0.5768\n",
      "Epoch 18/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.6969 - loss: 0.5704 - val_accuracy: 0.6896 - val_loss: 0.5764\n",
      "Epoch 19/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6977 - loss: 0.5702 - val_accuracy: 0.6897 - val_loss: 0.5777\n",
      "Epoch 20/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6970 - loss: 0.5704 - val_accuracy: 0.6914 - val_loss: 0.5761\n",
      "Epoch 21/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.6969 - loss: 0.5704 - val_accuracy: 0.6899 - val_loss: 0.5764\n",
      "Epoch 22/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6977 - loss: 0.5703 - val_accuracy: 0.6916 - val_loss: 0.5763\n",
      "Epoch 23/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6971 - loss: 0.5702 - val_accuracy: 0.6907 - val_loss: 0.5759\n",
      "Epoch 24/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6977 - loss: 0.5703 - val_accuracy: 0.6909 - val_loss: 0.5766\n",
      "Epoch 25/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.6985 - loss: 0.5699 - val_accuracy: 0.6884 - val_loss: 0.5782\n",
      "Epoch 26/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6978 - loss: 0.5700 - val_accuracy: 0.6909 - val_loss: 0.5783\n",
      "Epoch 27/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6976 - loss: 0.5702 - val_accuracy: 0.6910 - val_loss: 0.5757\n",
      "Epoch 28/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6976 - loss: 0.5702 - val_accuracy: 0.6919 - val_loss: 0.5758\n",
      "Epoch 29/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.6968 - loss: 0.5699 - val_accuracy: 0.6911 - val_loss: 0.5758\n",
      "Epoch 30/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6968 - loss: 0.5700 - val_accuracy: 0.6895 - val_loss: 0.5763\n",
      "Epoch 31/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6977 - loss: 0.5701 - val_accuracy: 0.6910 - val_loss: 0.5765\n",
      "Epoch 32/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6974 - loss: 0.5699 - val_accuracy: 0.6903 - val_loss: 0.5762\n",
      "Epoch 33/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.6977 - loss: 0.5699 - val_accuracy: 0.6898 - val_loss: 0.5763\n",
      "Epoch 34/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6977 - loss: 0.5698 - val_accuracy: 0.6912 - val_loss: 0.5768\n",
      "Epoch 35/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6976 - loss: 0.5699 - val_accuracy: 0.6909 - val_loss: 0.5766\n",
      "Epoch 36/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6975 - loss: 0.5697 - val_accuracy: 0.6890 - val_loss: 0.5771\n",
      "Epoch 37/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6973 - loss: 0.5699 - val_accuracy: 0.6914 - val_loss: 0.5767\n",
      "Epoch 38/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.6963 - loss: 0.5697 - val_accuracy: 0.6896 - val_loss: 0.5766\n",
      "Epoch 39/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.6983 - loss: 0.5696 - val_accuracy: 0.6911 - val_loss: 0.5772\n",
      "Epoch 40/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6980 - loss: 0.5696 - val_accuracy: 0.6904 - val_loss: 0.5786\n",
      "Epoch 41/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.6969 - loss: 0.5697 - val_accuracy: 0.6893 - val_loss: 0.5765\n",
      "Epoch 42/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6976 - loss: 0.5699 - val_accuracy: 0.6894 - val_loss: 0.5771\n",
      "Epoch 43/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6980 - loss: 0.5697 - val_accuracy: 0.6916 - val_loss: 0.5761\n",
      "Epoch 44/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.6978 - loss: 0.5696 - val_accuracy: 0.6895 - val_loss: 0.5765\n",
      "Epoch 45/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.6981 - loss: 0.5695 - val_accuracy: 0.6902 - val_loss: 0.5790\n",
      "Epoch 46/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6977 - loss: 0.5695 - val_accuracy: 0.6903 - val_loss: 0.5778\n",
      "Epoch 47/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6978 - loss: 0.5696 - val_accuracy: 0.6880 - val_loss: 0.5776\n",
      "Epoch 48/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6972 - loss: 0.5696 - val_accuracy: 0.6903 - val_loss: 0.5766\n",
      "Epoch 49/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6983 - loss: 0.5693 - val_accuracy: 0.6903 - val_loss: 0.5769\n",
      "Epoch 50/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6972 - loss: 0.5694 - val_accuracy: 0.6909 - val_loss: 0.5766\n",
      "Epoch 51/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6979 - loss: 0.5694 - val_accuracy: 0.6894 - val_loss: 0.5770\n",
      "Epoch 52/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.6977 - loss: 0.5693 - val_accuracy: 0.6892 - val_loss: 0.5782\n",
      "Epoch 53/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.6981 - loss: 0.5694 - val_accuracy: 0.6902 - val_loss: 0.5777\n",
      "Epoch 54/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6978 - loss: 0.5695 - val_accuracy: 0.6895 - val_loss: 0.5771\n",
      "Epoch 55/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6976 - loss: 0.5694 - val_accuracy: 0.6915 - val_loss: 0.5770\n",
      "Epoch 56/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.6987 - loss: 0.5694 - val_accuracy: 0.6893 - val_loss: 0.5769\n",
      "Epoch 57/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.6977 - loss: 0.5693 - val_accuracy: 0.6871 - val_loss: 0.5789\n",
      "Epoch 58/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.6976 - loss: 0.5693 - val_accuracy: 0.6877 - val_loss: 0.5805\n",
      "Epoch 59/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.6976 - loss: 0.5694 - val_accuracy: 0.6901 - val_loss: 0.5783\n",
      "Epoch 60/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6969 - loss: 0.5693 - val_accuracy: 0.6895 - val_loss: 0.5781\n",
      "Epoch 61/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6982 - loss: 0.5693 - val_accuracy: 0.6898 - val_loss: 0.5768\n",
      "Epoch 62/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.6969 - loss: 0.5693 - val_accuracy: 0.6902 - val_loss: 0.5766\n",
      "Epoch 63/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6976 - loss: 0.5693 - val_accuracy: 0.6903 - val_loss: 0.5782\n",
      "Epoch 64/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6983 - loss: 0.5694 - val_accuracy: 0.6901 - val_loss: 0.5769\n",
      "Epoch 65/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.6981 - loss: 0.5694 - val_accuracy: 0.6906 - val_loss: 0.5770\n",
      "Epoch 66/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6975 - loss: 0.5693 - val_accuracy: 0.6920 - val_loss: 0.5767\n",
      "Epoch 67/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6984 - loss: 0.5692 - val_accuracy: 0.6902 - val_loss: 0.5773\n",
      "Epoch 68/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.6975 - loss: 0.5694 - val_accuracy: 0.6899 - val_loss: 0.5774\n",
      "Epoch 69/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.6973 - loss: 0.5693 - val_accuracy: 0.6910 - val_loss: 0.5770\n",
      "Epoch 70/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6973 - loss: 0.5690 - val_accuracy: 0.6897 - val_loss: 0.5782\n",
      "Epoch 71/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6975 - loss: 0.5693 - val_accuracy: 0.6905 - val_loss: 0.5776\n",
      "Epoch 72/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6972 - loss: 0.5692 - val_accuracy: 0.6871 - val_loss: 0.5775\n",
      "Epoch 73/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6975 - loss: 0.5691 - val_accuracy: 0.6898 - val_loss: 0.5765\n",
      "Epoch 74/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.6986 - loss: 0.5690 - val_accuracy: 0.6906 - val_loss: 0.5765\n",
      "Epoch 75/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6977 - loss: 0.5691 - val_accuracy: 0.6879 - val_loss: 0.5772\n",
      "Epoch 76/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6978 - loss: 0.5693 - val_accuracy: 0.6900 - val_loss: 0.5768\n",
      "Epoch 77/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6971 - loss: 0.5692 - val_accuracy: 0.6911 - val_loss: 0.5767\n",
      "Epoch 78/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.6986 - loss: 0.5692 - val_accuracy: 0.6893 - val_loss: 0.5771\n",
      "Epoch 79/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.6981 - loss: 0.5692 - val_accuracy: 0.6885 - val_loss: 0.5777\n",
      "Epoch 80/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.6980 - loss: 0.5690 - val_accuracy: 0.6887 - val_loss: 0.5778\n",
      "Epoch 81/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.6981 - loss: 0.5692 - val_accuracy: 0.6892 - val_loss: 0.5769\n",
      "Epoch 82/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.6985 - loss: 0.5691 - val_accuracy: 0.6904 - val_loss: 0.5769\n",
      "Epoch 83/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.6973 - loss: 0.5691 - val_accuracy: 0.6878 - val_loss: 0.5771\n",
      "Epoch 84/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.6978 - loss: 0.5691 - val_accuracy: 0.6884 - val_loss: 0.5773\n",
      "Epoch 85/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6984 - loss: 0.5689 - val_accuracy: 0.6907 - val_loss: 0.5771\n",
      "Epoch 86/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.6984 - loss: 0.5691 - val_accuracy: 0.6916 - val_loss: 0.5774\n",
      "Epoch 87/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.6985 - loss: 0.5687 - val_accuracy: 0.6894 - val_loss: 0.5781\n",
      "Epoch 88/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.6976 - loss: 0.5692 - val_accuracy: 0.6906 - val_loss: 0.5774\n",
      "Epoch 89/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.6971 - loss: 0.5688 - val_accuracy: 0.6891 - val_loss: 0.5772\n",
      "Epoch 90/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.6975 - loss: 0.5689 - val_accuracy: 0.6906 - val_loss: 0.5768\n",
      "Epoch 91/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.6985 - loss: 0.5688 - val_accuracy: 0.6890 - val_loss: 0.5788\n",
      "Epoch 92/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.6991 - loss: 0.5689 - val_accuracy: 0.6910 - val_loss: 0.5771\n",
      "Epoch 93/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.6973 - loss: 0.5690 - val_accuracy: 0.6909 - val_loss: 0.5771\n",
      "Epoch 94/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.6984 - loss: 0.5690 - val_accuracy: 0.6880 - val_loss: 0.5782\n",
      "Epoch 95/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.6981 - loss: 0.5690 - val_accuracy: 0.6901 - val_loss: 0.5772\n",
      "Epoch 96/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.6973 - loss: 0.5689 - val_accuracy: 0.6896 - val_loss: 0.5776\n",
      "Epoch 97/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.6976 - loss: 0.5691 - val_accuracy: 0.6893 - val_loss: 0.5774\n",
      "Epoch 98/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.6983 - loss: 0.5690 - val_accuracy: 0.6894 - val_loss: 0.5773\n",
      "Epoch 99/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.6980 - loss: 0.5689 - val_accuracy: 0.6894 - val_loss: 0.5769\n",
      "Epoch 100/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.6981 - loss: 0.5689 - val_accuracy: 0.6897 - val_loss: 0.5772\n",
      "Epoch 101/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.6981 - loss: 0.5690 - val_accuracy: 0.6914 - val_loss: 0.5772\n",
      "Epoch 102/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.6986 - loss: 0.5691 - val_accuracy: 0.6893 - val_loss: 0.5770\n",
      "Epoch 103/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.6983 - loss: 0.5688 - val_accuracy: 0.6886 - val_loss: 0.5780\n",
      "Epoch 104/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.6980 - loss: 0.5691 - val_accuracy: 0.6911 - val_loss: 0.5786\n",
      "Epoch 105/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.6982 - loss: 0.5689 - val_accuracy: 0.6906 - val_loss: 0.5767\n",
      "Epoch 106/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.6987 - loss: 0.5688 - val_accuracy: 0.6899 - val_loss: 0.5774\n",
      "Epoch 107/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.6984 - loss: 0.5691 - val_accuracy: 0.6890 - val_loss: 0.5771\n",
      "Epoch 108/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.6980 - loss: 0.5689 - val_accuracy: 0.6903 - val_loss: 0.5767\n",
      "Epoch 109/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.6980 - loss: 0.5687 - val_accuracy: 0.6909 - val_loss: 0.5766\n",
      "Epoch 110/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.6992 - loss: 0.5689 - val_accuracy: 0.6898 - val_loss: 0.5768\n",
      "Epoch 111/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.6986 - loss: 0.5688 - val_accuracy: 0.6913 - val_loss: 0.5770\n",
      "Epoch 112/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.6989 - loss: 0.5688 - val_accuracy: 0.6889 - val_loss: 0.5780\n",
      "Epoch 113/5000\n",
      "\u001b[1m1258/1258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.6995 - loss: 0.5688 - val_accuracy: 0.6887 - val_loss: 0.5776\n",
      "Epoch 113: early stopping\n",
      "正解率: 69.75%\n"
     ]
    }
   ],
   "source": [
    "# 学習の実施\n",
    "history = model.fit(X_train, y_train, # 変数名を y_train\n",
    "                    epochs=5000,batch_size=32,verbose=1,\n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=100, verbose=1)], )\n",
    "\n",
    "# 評価\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'正解率: {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
